{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webdataset as wds\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "world_size: processes participating in job (e.g. 4)\n",
    "\n",
    "rank: index of current process (e.g. 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WORLD_SIZE'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5', '9', '3']\n",
      "['6', '2', '7']\n",
      "['1', '4']\n",
      "['8', '0']\n"
     ]
    }
   ],
   "source": [
    "for rank in range(4):\n",
    "    os.environ['RANK'] = str(rank)\n",
    "    print(list(wds.split_by_node({str(x) for x in range(10)})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nodesplitter_func(urls, node_id, node_count): # SimpleShardList\n",
    "    # print(urls)\n",
    "    # try:\n",
    "        # node_id, node_count = torch.distributed.get_rank(), torch.distributed.get_world_size()\n",
    "    urls_to_use = list(urls)[node_id::node_count]\n",
    "    print(f'id: {node_id}, of count {node_count}. \\nURLS: {len(urls_to_use)} of {len(urls)} ({urls_to_use})\\n\\n')\n",
    "    # except RuntimeError:\n",
    "    #     # print('Distributed not initialised. Hopefully single node.')\n",
    "    return urls_to_use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 0, of count 4. \n",
      "URLS: 3 of 10 (['5', '9', '3'])\n",
      "\n",
      "\n",
      "['5', '9', '3']\n",
      "id: 1, of count 4. \n",
      "URLS: 3 of 10 (['6', '2', '7'])\n",
      "\n",
      "\n",
      "['6', '2', '7']\n",
      "id: 2, of count 4. \n",
      "URLS: 2 of 10 (['1', '4'])\n",
      "\n",
      "\n",
      "['1', '4']\n",
      "id: 3, of count 4. \n",
      "URLS: 2 of 10 (['8', '0'])\n",
      "\n",
      "\n",
      "['8', '0']\n"
     ]
    }
   ],
   "source": [
    "for rank in range(4):\n",
    "    os.environ['RANK'] = str(rank)\n",
    "    print(nodesplitter_func({str(x) for x in range(10)}, rank, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 0, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wds.utils.pytorch_worker_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '2']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def get_per_worker(urls={str(x) for x in range(10)}, worker_n=1, num_workers=5):\n",
    "    for s in islice(urls, worker_n, None, num_workers):\n",
    "        yield s\n",
    "\n",
    "list(get_per_worker(worker_n=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
